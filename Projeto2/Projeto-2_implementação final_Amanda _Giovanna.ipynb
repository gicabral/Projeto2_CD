{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "## Giovanna Cabral e Amanda Rufino - 2A\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>positividade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@samsungbrasil j5 prime samsung. meu cartão ai...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minha tia falando que não troca samsung por ap...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @beatriz5correia: pls rt para encontrar o m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@michaelserra aqui só se for com rom customiza...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  relevancia  positividade\n",
       "0  @samsungbrasil j5 prime samsung. meu cartão ai...           0             1\n",
       "1  minha tia falando que não troca samsung por ap...           1             0\n",
       "2  rt @beatriz5correia: pls rt para encontrar o m...           0             0\n",
       "3  @michaelserra aqui só se for com rom customiza...           1             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados= pd.read_excel('tweets_samsung_classificados.xlsx')\n",
    "dados.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gi_gi\\Anaconda3\\ciência dos dados\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "index=0\n",
    "for frase in dados[\"Treinamento\"]:\n",
    "    if index<=299:\n",
    "        frase_new=re.split(\" \", frase)\n",
    "        dados[\"Treinamento\"][index]=frase_new\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gi_gi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gi_gi\\Anaconda3\\ciência dos dados\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "index=0\n",
    "import string \n",
    "\n",
    "print(string.punctuation)\n",
    "#remove ponctuation from each word \n",
    "\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for e in dados[\"Treinamento\"]:\n",
    "    if index<=299:\n",
    "        sem_pontuacao=[w.translate(table) for w in dados[\"Treinamento\"][index]]\n",
    "        dados[\"Treinamento\"][index]=sem_pontuacao\n",
    "        index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "palavras_neg_list=[]\n",
    "palavras_pos_list=[]\n",
    "palavras_irrel_list=[]\n",
    "palavras_rel_list=[]\n",
    "palavras_possiveis=[]\n",
    "    \n",
    "for e in dados[\"relevancia\"]:\n",
    "    for i in dados[\"Treinamento\"][index]:\n",
    "        palavras_possiveis.append(i)\n",
    "        \n",
    "    if e==1:  # relevante.\n",
    "        for i in dados[\"Treinamento\"][index]:\n",
    "            palavras_rel_list.append(i)\n",
    "            \n",
    "        if dados[\"positividade\"][index] == 0:\n",
    "             for i in dados[\"Treinamento\"][index]:\n",
    "                palavras_neg_list.append(i)\n",
    "        else:\n",
    "             for i in dados[\"Treinamento\"][index]:\n",
    "                palavras_pos_list.append(i)\n",
    "    else:\n",
    "        for i in dados[\"Treinamento\"][index]:\n",
    "            palavras_irrel_list.append(i)\n",
    "\n",
    "    index+=1\n",
    "\n",
    "def fazDicionario(lista):\n",
    "    dicionario={}\n",
    "    for p in lista:\n",
    "        if p not in dicionario:\n",
    "            dicionario[p]=0\n",
    "        dicionario[p]+=1\n",
    "            \n",
    "    return dicionario\n",
    "        \n",
    "palavras_irrel=fazDicionario(palavras_irrel_list)\n",
    "palavras_rel=fazDicionario(palavras_rel_list)\n",
    "palavras_neg=fazDicionario(palavras_neg_list)\n",
    "palavras_pos=fazDicionario(palavras_pos_list)\n",
    "num_relevante=fazDicionario(dados[\"relevancia\"])\n",
    "num_positividade=fazDicionario(dados[\"positividade\"])\n",
    "    \n",
    "# https:\n",
    "def remove_repetidos(lista):\n",
    "    l = []\n",
    "    for i in lista:\n",
    "        if i not in l:\n",
    "            l.append(i)\n",
    "    l.sort()\n",
    "    return l\n",
    "\n",
    "palavras_possiveis=remove_repetidos(palavras_possiveis)\n",
    "palavras_rel_unicas=remove_repetidos(palavras_rel)\n",
    "\n",
    "stop_words=nltk.corpus.stopwords.words('portuguese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets_teste.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-585cb89d12ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets_teste.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\ciência dos dados\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\ciência dos dados\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\ciência dos dados\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32m~\\Anaconda3\\ciência dos dados\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\Anaconda3\\ciência dos dados\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets_teste.xlsx'"
     ]
    }
   ],
   "source": [
    "data= pd.read_excel('tweets_teste.xlsx')\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for frase in data[\"Teste\"]:\n",
    "    if index<=199:\n",
    "        frase_new=re.split(\" \", frase)\n",
    "        data[\"Teste\"][index]=frase_new\n",
    "       \n",
    "        sem_pontuacao=[w.translate(table) for w in data[\"Teste\"][index]]\n",
    "        data[\"Teste\"][index]=sem_pontuacao\n",
    "        index+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "prob_irrel=math.log(num_relevante[0]/(num_relevante[0]+num_relevante[1]))\n",
    "prob_rel=math.log(num_relevante[1]/(num_relevante[0]+num_relevante[1]))\n",
    "\n",
    "frases_relevantes=[]\n",
    "frases_irrelevantes=[]\n",
    "\n",
    "i=0\n",
    "while i<199:\n",
    "    multiplicacao_prob_rel=0\n",
    "    multiplicacao_prob_irrel=0\n",
    " \n",
    "    frase=data[\"Teste\"][i]\n",
    "    for palavra in frase:\n",
    "        #probabilidade da frase ser relevante:\n",
    "        if palavra not in stop_words:\n",
    "            quantidade_contagem = 1\n",
    "            quantidade_contagem_ir = 1\n",
    "            \n",
    "            if palavra in palavras_rel:\n",
    "                quantidade_contagem+=palavras_rel[palavra]\n",
    "\n",
    "            multiplicacao_prob_rel+=math.log((quantidade_contagem/(len(palavras_rel_list)+len(palavras_possiveis)))) #suavizado por laplace \n",
    "        #probabilidade da frase ser irrelevante:    \n",
    "            \n",
    "            if palavra in palavras_irrel:\n",
    "                quantidade_contagem_ir+=palavras_irrel[palavra]\n",
    "            \n",
    "            multiplicacao_prob_irrel+=math.log((quantidade_contagem_ir/(len(palavras_irrel_list)+len(palavras_possiveis))))\n",
    "\n",
    "    multiplicacao_prob_irrel+=prob_irrel    \n",
    "    multiplicacao_prob_rel+=prob_rel\n",
    "    \n",
    "    data[\"positividade_programa\"]=0\n",
    "    if multiplicacao_prob_rel>multiplicacao_prob_irrel:\n",
    "        frases_relevantes.append(frase)\n",
    "        frases_relevantes.append(i)\n",
    "        data[\"relevante_programa\"][i]=1\n",
    "        \n",
    "    else:\n",
    "        frases_irrelevantes.append(frase)\n",
    "        data[\"relevante_programa\"][i]=0\n",
    "        \n",
    "    i+=1\n",
    "    \n",
    "\n",
    "print(frases_relevantes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos=math.log(num_positividade[1]/(num_positividade[0]+num_positividade[1]))\n",
    "prob_neg=math.log(num_positividade[0]/(num_positividade[0]+num_positividade[1]))\n",
    "\n",
    "\n",
    "frases_positivas=[]\n",
    "frases_negativas=[]\n",
    "\n",
    "i=0\n",
    "while i<len(frases_relevantes):\n",
    "    multiplicacao_prob_pos=0\n",
    "    multiplicacao_prob_neg=0\n",
    " \n",
    "    frase=frases_relevantes[i]\n",
    "   \n",
    "    for palavra in frase:\n",
    "        #probabilidade da frase ser relevante:\n",
    "        if palavra not in stop_words:\n",
    "            quantidade_contagem_pos = 1\n",
    "            quantidade_contagem_neg = 1\n",
    "            \n",
    "            if palavra in palavras_pos:\n",
    "                quantidade_contagem_pos+=palavras_pos[palavra]\n",
    "\n",
    "            multiplicacao_prob_pos+=math.log((quantidade_contagem_pos/(len(palavras_pos_list)+len(palavras_rel_unicas)))) #suavizado por laplace \n",
    "        #probabilidade da frase ser irrelevante:    \n",
    "            \n",
    "            if palavra in palavras_neg:\n",
    "                quantidade_contagem_neg+=palavras_neg[palavra]\n",
    "            \n",
    "            multiplicacao_prob_neg+=math.log((quantidade_contagem_neg/(len(palavras_neg_list)+len(palavras_rel_unicas))))\n",
    "\n",
    "    multiplicacao_prob_neg+=prob_neg    \n",
    "    multiplicacao_prob_pos+=prob_pos\n",
    "    \n",
    "    \n",
    "    if multiplicacao_prob_pos>multiplicacao_prob_neg:\n",
    "        frases_positivas.append(frase)\n",
    "        data[\"positividade_programa\"][i+1]=1\n",
    "        \n",
    "    else:\n",
    "        frases_negativas.append(frase)\n",
    "        data[\"positividade_programa\"][i+1]=0\n",
    "        \n",
    "    i+=2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantes_verd=0\n",
    "relevantes_falsos=0\n",
    "irrelevantes_falsos=0\n",
    "irrelevantes_verd=0\n",
    "i=0\n",
    "erro=0\n",
    "while i<199:\n",
    "    if data[\"relevante\"][i]==1:\n",
    "        if data[\"relevante_programa\"][i]==0:\n",
    "            relevantes_falsos+=1\n",
    "        if data[\"relevante_programa\"][i]==1:\n",
    "            relevantes_verd+=1\n",
    "            \n",
    "    if data['relevante'][i]==0:#irrelevantes --> 98\n",
    "        if data['relevante_programa'][i]==0:\n",
    "            irrelevantes_verd+=1\n",
    "        if data['relevante_programa'][i]==1:\n",
    "            irrelevantes_falsos+=1\n",
    "            \n",
    "    i+=1\n",
    "    \n",
    "print(relevantes_verd)\n",
    "print(relevantes_falsos)\n",
    "\n",
    "n_relevante=fazDicionario(data[\"relevante\"])\n",
    "\n",
    "print(relevantes_verd/n_relevante[1]*100) #probabilidade do programa ter colocado como relevante uma frase que nós \n",
    "#tinhamos colocado como relevantes também\n",
    "print(irrelevantes_verd/n_relevante[0]*100) #probabilidade do programa ter colocado como irrelevante\n",
    "#dadas as frases colocadas por nos como irrelevantes\n",
    "print(irrelevantes_falsos/n_relevante[0]*100)\n",
    "print((relevantes_verd+irrelevantes_verd)/(n_relevante[0]+n_relevante[1])*100) #probabilidade de ter havido um acerto dado todo \n",
    "#o conjunto de frases classificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acerto_verd=0\n",
    "acerto_falso=0\n",
    "acerto_verd_s=0\n",
    "acerto_falso_s=0\n",
    "i=0\n",
    "while i<199:\n",
    "    if data[\"relevante_programa\"][i]==1: \n",
    "        ### nessa parte o programa faz a comparação de ter acertado (ter correspondencia entre \n",
    "        #oq foi feito por nos e coloca do ele, dentro de todo o grupo de palavras que ele classificoi como relevantes, \n",
    "        #sem necessariamente considerar seus próprios erros)\n",
    "        if data[\"positividade_programa\"][i]==data[\"positividade\"][i]:\n",
    "             acerto_verd_s+=1\n",
    "        else:\n",
    "            acerto_falso_s+=1\n",
    "        #Já nessa outra parte o programa verifica se houve acerto para as frases que o programa acertou como relevantes,\n",
    "        #ou seja, nessa parte só entram os relevantes do programa que tmabém foram considerados por nós como relevantes.\n",
    "        if data[\"relevante\"][i]==1:\n",
    "            if data[\"positividade_programa\"][i]==data[\"positividade\"][i]:\n",
    "                acerto_verd+=1\n",
    "            else:\n",
    "                acerto_falso+=1\n",
    "                \n",
    "    i+=1 \n",
    "print(acerto_verd)\n",
    "print(acerto_falso)\n",
    "print(acerto_verd_s/(len(frases_relevantes)/2)*100)\n",
    "print(acerto_verd/(n_relevante[0]+n_relevante[1])*100)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados obtidos pelo classificador pode-se concluir que há uma probabilidade de acerto de 74%. Dada uma certa frase classificada por nós como relevante há 86% de chance do classificador também ter marcado como relevante. Do mesmo, dada uma frase classificada por nós como irrelevante há 61% de chance do classificador ter marcado como irrelevante. Assim, percebemos que há uma maior chance de erro para frases irrelevantes, o que pode ser explicado pela maior quantidade de frases repetidas no banco de dados irrelevantes, o que diminuiu a precisão do classificador.\n",
    "\n",
    "Além disso, o classificador realiza uma segunda classificação para as frases, caso essas sejam consideradas relevantes. Dado um conjunto de frases recebido por ele, a chance dele acertar a classificação, ou seja, colocar uma resposta correspondente a colocada por nós, é de 70%. No entanto, como já há um erro nessa segunda lista em que ele analisa, visto que o classificador tem uma chance de classificar como relevante sem o ser, o número da combinação é de 30,5%. \n",
    "\n",
    "Por fim, a chance de, dado um conjunto de dados, classificar tanto como relevante corretamente, quanto como positivo/negativo corretamente é de 30%. Apesar do numero parecer pequeno, é bastante satisfatório, pois na segunda passagem, há razoáveis erros na lista classificada, que pode ter relevantes, que não o são, quanto pode faltar relevantes que foram por nós considerado, e com base nessa lista com frases que sobram e frases que faltam que é feita a segunda classificação que também tem uma margem de erro. \n",
    "\n",
    "Assim, percebe-se que para melhorar a precisão final do classificador, pode ser implementado melhorias no sentido de aumentar a sensibilidade para os relevantes, a fim de que mais frases possam passar pela segunda classificação. No entanto, o programa ainda é muito simples e traz resultados que demonstram que cada etapa apesar de funcionar bem separadamente,ao serem combinadas não tem alta precisão, o que indica a necessidade de que uma pessoa avalie os dados coletados a partir de duas passgens pelo Naive-Baise confeccionado por nós. \n",
    "\n",
    "Além disso, as frases que haviam ironia e duplo sentido são classificadas por nós como interpretações do sentido expressado pela frase, mas não necessariamente as palavras exclusivamente ajudem a afirmar a relevância ou não, nem a sua positividade ou não, de modo que esse conteúdo também pode ter atrapalhado no sucesso das correspondências.\n",
    "\n",
    "O classificador Naive-Bayes pode ser utilizado para diferentes propósitos, além da classificação de tweets, como aplicado nesse projeto. Outra aplicação para esse classificador seria para diagnósticos médicos. Por exemplo, em um diagnóstico médico existem duas classes possíveis: o paciente tem H1N1 e o paciente não tem H1N1. Além disso, as características possíveis são resultados de um exame com duas possíveis classificações, positivo e negativo. Assim, tendo o conhecimento da probabilidade da população ter essa doença e sabendo a probabibilidade do exame retornar um resultado positivo correto e retorna um resultado negativo correto é possível fazer o diagnóstico médico de determinada pessoa, através do classificador Naive-Bayes. \n",
    "\n",
    "Além de ser implementado para diagnósticos médicos, o classificador pode ser utilizado para detecção de fraudes, ou seja, para  identificar se uma transação financeira é “legal” ou “suspeita”, para programas de filtragem de spam, ou seja, detectar se e-mail é um spam ou não. Outro propósito possível seria a aprovação de crédito, ou seja, classificar um cliente de acordo com o risco que ele irá trazer para a concessão de crédito. Consequentemente, pode-se concluir que o classificador Naive-Bayes tem várias aplicações com diferentes propósitos e grande utilidade. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
